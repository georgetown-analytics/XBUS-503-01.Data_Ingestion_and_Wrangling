{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITANIC: Wrangling the Passenger Manifest\n",
    "\n",
    "## Exploratory Analysis with ```Pandas```\n",
    "On April 15, 1912, the RMS Titanic sunk after hitting an iceberg, killing 1502 out of 2224 passengers and crew about during her maiden voyage. While luck did play a role in the survival of some passengers, certain groups&mdash;women and childen&mdash;were much more likely to survive.\n",
    "\n",
    "In this tutorial you will gain experience using ```pandas``` to visualize and clean data from the Titanic's passenger manifest. Afterwards it is also recommended that you complete the \"additional_wrangling_challenge\" notebook, which expands on these skills and is included in this course's repository.\n",
    "\n",
    "**Be sure to read the README before you begin!** In addition, you may also find these resources helpful:  \n",
    "https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/\n",
    "https://chrisalbon.com/python/pandas_dataframe_descriptive_stats.html\n",
    "\n",
    "*This tutorial is based on the Kaggle Competition, \"Predicting Survival Aboard the Titanic\" https://www.kaggle.com/c/titanic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "The file we'll be exploring today, ```train.csv```, represents a subset of the Titanic's passenger manifest. It was downloaded when you cloned X503's GitHub repo and is located in the ```Data``` folder. The remaining data from the passenger manifest is in ```test.csv```, which is saved in the same folder and we'll use later on in the Machine Learning course. But for now, let's load the ```train.csv``` file and start exploring the data.\n",
    "\n",
    "=> Load the ```train.csv``` file into a ```pandas``` ```DataFrame```.\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train.csv file as a dataframe using pandas: df\n",
    "df ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Use ```pandas``` to view the \"head\" of the file with the first 10 rows.\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to view the first 10 rows of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you see? When exploring a new data set, these are some of the first questions you should try to answer.*\n",
    " * Are there any missing values?\n",
    " * What kinds of values/numbers/text are there?\n",
    " * Are the values continuous or categorical?\n",
    " * Are some variables more sparse than others?\n",
    " * Are there multiple values in a single column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics\n",
    "\n",
    "__=>__ Use ```pandas``` to get summary statistics on the numerical fields in the data.\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to get the summary statistics on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What can we infer from the summary statistics?*\n",
    " * How many missing values does the ```Age``` column have?\n",
    " * What percentage of the passengers survived?\n",
    " * How many passengers traveled in Class 3?\n",
    " * Are there any outliers in the ```Fare``` column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__=>__ Use ```pandas``` to get the median of the ```Age``` column.\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.median.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to get the median of the Age column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__=>__ Use ```pandas``` to find the number of unique values in the ```Ticket``` column.\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nunique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to find the number of unique values in the Ticket column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Ticket``` column has a large number of unique values. As we saw above in our initial exploration of the data, this feature includes a combination of text and numerical data. Therefore, let's use ```value_counts()``` to generate a frequency distribution of the ```Ticket``` values, so we can see whether this data will be useful for our models.\n",
    "\n",
    "__=>__ Use ```pandas``` to count the number of each unique value in the ```Ticket``` column.\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/version/0.20.3/generated/pandas.Series.value_counts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to count the number of each unique Ticket value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "Now let's look at two histograms of the ```Fare``` data. In the first, we'll set ```bins=10``` and in the second ```bin=50```. Which one do you find the most helpful? What are you able to tell about the range of fares paid by the passengers from the histograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,10))\n",
    "ax = fig.add_subplot(211)\n",
    "ax.hist(df['Fare'], bins=10, range=(df['Fare'].min(),df['Fare'].max()))\n",
    "plt.title('Fare Distribution with 10 Bins')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Count of Passengers')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(7,10))\n",
    "ax = fig.add_subplot(212)\n",
    "ax.hist(df['Fare'], bins=50, range=(df['Fare'].min(),df['Fare'].max()))\n",
    "plt.title('Fare Distribution with 50 Bins')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Count of Passengers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "It's important to wrangle your data before building your models, since ```scikit-learn``` cannot process missing values and only accepts numerical data. Outliers should also be dealt with beforehand, since they will negatively impact the performance of most machine learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "When examining the histograms of the ```Fare``` data, did you notice any potential outliers? Since there is a relationship between the cost of a ticket and the class the passenger was traveling in, let's look at a box plot of this data to investigate further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9,7))\n",
    "sns.boxplot(x='Pclass', y='Fare', data=df, palette='vlag')\n",
    "sns.swarmplot(x='Pclass', y='Fare', data=df, size=2, color='0.3')\n",
    "plt.title('Ticket Cost By Class', size=14)\n",
    "plt.xlabel('Ticket Class', size=12)\n",
    "plt.ylabel('Fares', size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly see that there a few first-class fares that are much higher than the others. Let's sort the data set by the ```Fare``` column so we can see the cost of the most expensive tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Fare', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ```$512``` fares appear to be outliers, let's replace them with ```$213```, since it is the second highest value and much closer to the other data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in df.index:\n",
    "    if df.loc[idx].Fare > 500:\n",
    "        df.set_value(idx, 'Fare', 263.0000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Data\n",
    "When deciding how to handle missing values, it is important to know how prevalent they are in your data. Let's use ```pandas``` to find out how many ```Cabin``` values are missing from our data set.\n",
    "\n",
    "__=>__ Use ```pandas``` to get the sum of all the null values in the ```Cabin``` column.\n",
    "\n",
    "Documentation:    \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html    \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum the number of null Cabin values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting a Feature\n",
    "\n",
    "\n",
    "__=>__ Since most of the ```Cabin``` values are missing, let's use ```pandas``` to drop the column. We will also drop the ```Ticket``` column, since as we saw earlier, it contains of a mix of text and numeric data that doesn't appear to contain any useful information. *HINT: remember to set ```axis=1```.*\n",
    "\n",
    "Documentation:  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html  \n",
    "https://chrisalbon.com/python/pandas_dropping_column_and_rows.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to drop the Cabin and Ticket columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in Missing Data\n",
    "While the ```Age``` column also contains null values, it is missing far fewer than the ```Cabin``` column, so we will fill those in rather than drop the column. The simplest approach, which we'll use here, is to replace the null values with the mean age of the passengers.\n",
    "\n",
    "__=>__ First use ```pandas``` to calculate and save the mean age of the passengers. Then replace the null values in the ```Age``` column with that number.\n",
    "\n",
    "Documentation:  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html     \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, use pandas to find the mean age of the passengers: mean_age\n",
    "mean_age = \n",
    "\n",
    "# ...and then fill in the null Age values with mean_age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that there are no more null values in the Age column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Your Work\n",
    "...you will need it in a few weeks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas.io.sql as pd_sql\n",
    "import sqlite3 as sql\n",
    "\n",
    "# Create a sqlite3 database to store the data.\n",
    "con = sql.connect('titanic.db') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__=>__ Use ```pandas``` to write your ```DataFrame``` to the ```sqlite``` database.\n",
    "\n",
    "Documenation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to save your dataframe to a sqlite database name 'training_data'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
